{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C8501BF0aoYZ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8501BF0aoYZ",
        "outputId": "f7eb9d77-cf54-4d62-bdc0-276a67390ae5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# !ls /content/drive/My\\ Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hUBLtl8Faq7w",
      "metadata": {
        "id": "hUBLtl8Faq7w"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NTsbOWfNatAf",
      "metadata": {
        "id": "NTsbOWfNatAf"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_dir = '/content/drive/MyDrive/dataset_train'\n",
        "test_dir = '/content/drive/MyDrive/dataset_test'\n",
        "test_dir2 = '/content/drive/MyDrive/datasetMe'\n",
        "grad_dir = '/content/drive/MyDrive/gradCam'\n",
        "augment_dir = '/content/drive/MyDrive/augment_dir'\n",
        "val_dir = '/content/drive/MyDrive/val_dir'\n",
        "cam_dir = '/content/drive/MyDrive/CAM_test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SoAQt4NKojc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoAQt4NKojc8",
        "outputId": "32ee2fc5-db57-4e7e-ee83-10f88841e923"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import shutil\n",
        "\n",
        "\n",
        "img_size = 224\n",
        "batch_size = 32\n",
        "augmentation_save_dir = augment_dir\n",
        "validation_save_dir = val_dir\n",
        "\n",
        "os.makedirs(augmentation_save_dir, exist_ok=True)\n",
        "os.makedirs(validation_save_dir, exist_ok=True)\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=25,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.3,\n",
        "    zoom_range=0.3,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "for category in os.listdir(train_dir):\n",
        "    category_path = os.path.join(train_dir, category)\n",
        "    save_augmentation_category_path = os.path.join(augmentation_save_dir, category)\n",
        "    save_validation_category_path = os.path.join(validation_save_dir, category)\n",
        "    os.makedirs(save_augmentation_category_path, exist_ok=True)\n",
        "    os.makedirs(save_validation_category_path, exist_ok=True)\n",
        "\n",
        "    if os.path.isdir(category_path):\n",
        "        images = [img for img in os.listdir(category_path) if img.lower().endswith(('png', 'jpg', 'jpeg'))]\n",
        "        num_validation = len(images) // 2\n",
        "\n",
        "        # 分配到驗證集\n",
        "        for img_name in images[:num_validation]:\n",
        "            shutil.copy(os.path.join(category_path, img_name), os.path.join(save_validation_category_path, img_name))\n",
        "\n",
        "        # 剩下的一半進行數據增強，放大三倍\n",
        "        for img_name in images[num_validation:]:\n",
        "            img_path = os.path.join(category_path, img_name)\n",
        "            img = tf.keras.utils.load_img(img_path, target_size=(img_size, img_size))\n",
        "            img_array = tf.keras.utils.img_to_array(img)\n",
        "            img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "            # 保存原始圖片\n",
        "            shutil.copy(img_path, os.path.join(save_augmentation_category_path, img_name))\n",
        "\n",
        "\n",
        "            i = 0\n",
        "            for batch in datagen.flow(img_array, batch_size=1, save_to_dir=save_augmentation_category_path,\n",
        "                                      save_prefix='aug', save_format='jpeg'):\n",
        "                i += 1\n",
        "                if i >= 5:\n",
        "                    break\n",
        "\n",
        "print(\"augmentation and split done\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ztJFMyrhvaUo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztJFMyrhvaUo",
        "outputId": "fbfa4654-6764-4a5e-9cd3-27f9cb82d0e0"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory=augmentation_save_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    directory=validation_save_dir,\n",
        "    target_size=(img_size, img_size),\n",
        "    color_mode='rgb',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "nU170bz4xUN5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "nU170bz4xUN5",
        "outputId": "b0c03fe9-abf5-4721-ef9b-c99a25512737"
      },
      "outputs": [],
      "source": [
        "images, labels = next(train_generator)\n",
        "\n",
        "\n",
        "num_images_to_display = 25\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "for i in range(num_images_to_display):\n",
        "    plt.subplot(5,5, i + 1)\n",
        "    plt.imshow(images[i].squeeze(), cmap='gray')\n",
        "    plt.title(f\"Label: {np.argmax(labels[i])}\")\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IUHttatSawlj",
      "metadata": {
        "id": "IUHttatSawlj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dense(128, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
        "x = Dropout(0.6)(x)\n",
        "x = Dense(32, activation='relu', kernel_regularizer=l2(1e-4))(x)\n",
        "x = Dropout(0.6)(x)\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X55PFIQmMhHR",
      "metadata": {
        "id": "X55PFIQmMhHR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "cam_dir = '/content/drive/MyDrive/CAM_test'\n",
        "\n",
        "def grad_cam(model, image, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        inputs=model.input,\n",
        "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(image)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "\n",
        "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0) / (np.max(heatmap) + 1e-8)  # 確保不除以 0\n",
        "    return heatmap\n",
        "\n",
        "\n",
        "# 生成 Grad-CAM 疊加圖像\n",
        "def generate_grad_cam_image(original_image, heatmap, alpha=0.4):\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    jet = plt.cm.get_cmap(\"jet\")\n",
        "    jet_heatmap = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_heatmap[heatmap]\n",
        "\n",
        "    jet_heatmap = tf.image.resize(jet_heatmap, (original_image.shape[0], original_image.shape[1]))\n",
        "    jet_heatmap = np.uint8(255 * jet_heatmap.numpy())\n",
        "\n",
        "\n",
        "    superimposed_img = jet_heatmap * alpha + original_image / 255.0\n",
        "    superimposed_img = np.clip(superimposed_img, 0, 1)\n",
        "    return superimposed_img\n",
        "\n",
        "class GradCamCallback(Callback):\n",
        "    def __init__(self, images, labels, last_conv_layer_name, save_dir=\"gradcam_output\"):\n",
        "        super(GradCamCallback, self).__init__()\n",
        "        self.images = images  \n",
        "        self.labels = labels  # 圖片對應的真實標籤\n",
        "        self.last_conv_layer_name = last_conv_layer_name\n",
        "        self.save_dir = save_dir\n",
        "        os.makedirs(self.save_dir, exist_ok=True)\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for i, image in enumerate(self.images):\n",
        "            heatmap = grad_cam(self.model, np.expand_dims(image, axis=0), self.last_conv_layer_name)  # 使用 self.model\n",
        "            grad_cam_image = generate_grad_cam_image(image, heatmap)\n",
        "\n",
        "\n",
        "            plt.figure(figsize=(5, 5))\n",
        "            plt.imshow(grad_cam_image)\n",
        "            plt.title(f\"True Label: {self.labels[i]}\")\n",
        "            plt.axis('off')\n",
        "            plt.savefig(os.path.join(self.save_dir, f\"epoch_{epoch + 1}_img_{self.labels[i]}.png\"))\n",
        "            plt.close()\n",
        "        print(f\"Grad-CAM images for epoch {epoch + 1} saved to {self.save_dir}\")\n",
        "\n",
        "\n",
        "sample_dir = cam_dir\n",
        "image_paths = [os.path.join(sample_dir, fname) for fname in os.listdir(sample_dir)]\n",
        "sample_images = []\n",
        "sample_labels = []\n",
        "\n",
        "for img_path in image_paths:\n",
        "    label = os.path.splitext(os.path.basename(img_path))[0]\n",
        "    img = load_img(img_path, target_size=(224, 224))\n",
        "    img_array = img_to_array(img) / 255.0\n",
        "    sample_images.append(img_array)\n",
        "    sample_labels.append(label)\n",
        "\n",
        "sample_images = np.array(sample_images)\n",
        "\n",
        "\n",
        "grad_cam_callback = GradCamCallback(\n",
        "    # model=model,\n",
        "    images=sample_images,\n",
        "    labels=sample_labels,\n",
        "    last_conv_layer_name=\"Conv_1\",\n",
        "    save_dir= grad_dir\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5-G7LfkjazkK",
      "metadata": {
        "id": "5-G7LfkjazkK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=8,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.5,\n",
        "    patience=3,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "\n",
        "history_initial = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=50,\n",
        "    batch_size=128,\n",
        "    callbacks=[grad_cam_callback,early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "\n",
        "for layer in base_model.layers[-20:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "history_finetune = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    callbacks=[grad_cam_callback,early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "model.save(\"FER_900_data_mobilenetv2.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KQlnlAdIswPi",
      "metadata": {
        "id": "KQlnlAdIswPi"
      },
      "outputs": [],
      "source": [
        "# 7 emotions x 4 people x 1 picture\t  = 28\n",
        "loss, accuracy = model.evaluate(test_generator)\n",
        "print(f\"Test Loss: {loss}\")\n",
        "print(f\"Test Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b33088e",
      "metadata": {
        "id": "4b33088e"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "initial_epochs = len(history_initial.history['accuracy'])\n",
        "total_epochs = initial_epochs + len(history_finetune.history['accuracy'])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, initial_epochs + 1), history_initial.history['accuracy'], label='Initial Training Accuracy')\n",
        "plt.plot(range(1, initial_epochs + 1), history_initial.history['val_accuracy'], label='Initial Validation Accuracy')\n",
        "plt.plot(range(initial_epochs + 1, total_epochs + 1), history_finetune.history['accuracy'], label='Fine-tuning Training Accuracy', linestyle='--')\n",
        "plt.plot(range(initial_epochs + 1, total_epochs + 1), history_finetune.history['val_accuracy'], label='Fine-tuning Validation Accuracy', linestyle='--')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy Over Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(range(1, initial_epochs + 1), history_initial.history['loss'], label='Initial Training Loss')\n",
        "plt.plot(range(1, initial_epochs + 1), history_initial.history['val_loss'], label='Initial Validation Loss')\n",
        "plt.plot(range(initial_epochs + 1, total_epochs + 1), history_finetune.history['loss'], label='Fine-tuning Training Loss', linestyle='--')\n",
        "plt.plot(range(initial_epochs + 1, total_epochs + 1), history_finetune.history['val_loss'], label='Fine-tuning Validation Loss', linestyle='--')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss Over Epochs\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
